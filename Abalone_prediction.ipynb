{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers, optimizers, models\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import Image, SVG\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "# from skrvm import RVR\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3       4       5       6       7   8\n",
       "0     M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.1500  15\n",
       "1     M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.0700   7\n",
       "2     F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.2100   9\n",
       "3     M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.1550  10\n",
       "4     I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.0550   7\n",
       "...  ..    ...    ...    ...     ...     ...     ...     ...  ..\n",
       "4172  F  0.565  0.450  0.165  0.8870  0.3700  0.2390  0.2490  11\n",
       "4173  M  0.590  0.440  0.135  0.9660  0.4390  0.2145  0.2605  10\n",
       "4174  M  0.600  0.475  0.205  1.1760  0.5255  0.2875  0.3080   9\n",
       "4175  F  0.625  0.485  0.150  1.0945  0.5310  0.2610  0.2960  10\n",
       "4176  M  0.710  0.555  0.195  1.9485  0.9455  0.3765  0.4950  12\n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"abalone.data\", encoding=\"UTF-8\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3       4       5       6       7   8\n",
       "0     2  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.1500  15\n",
       "1     2  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.0700   7\n",
       "2     0  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.2100   9\n",
       "3     2  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.1550  10\n",
       "4     1  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.0550   7\n",
       "...  ..    ...    ...    ...     ...     ...     ...     ...  ..\n",
       "4172  0  0.565  0.450  0.165  0.8870  0.3700  0.2390  0.2490  11\n",
       "4173  2  0.590  0.440  0.135  0.9660  0.4390  0.2145  0.2605  10\n",
       "4174  2  0.600  0.475  0.205  1.1760  0.5255  0.2875  0.3080   9\n",
       "4175  0  0.625  0.485  0.150  1.0945  0.5310  0.2610  0.2960  10\n",
       "4176  2  0.710  0.555  0.195  1.9485  0.9455  0.3765  0.4950  12\n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "data[0] = labelencoder.fit_transform(data[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_max = data[8].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3       4       5       6       7         8\n",
       "0     1.0  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.1500  0.517241\n",
       "1     1.0  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.0700  0.241379\n",
       "2     0.0  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.2100  0.310345\n",
       "3     1.0  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.1550  0.344828\n",
       "4     0.5  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.0550  0.241379\n",
       "...   ...    ...    ...    ...     ...     ...     ...     ...       ...\n",
       "4172  0.0  0.565  0.450  0.165  0.8870  0.3700  0.2390  0.2490  0.379310\n",
       "4173  1.0  0.590  0.440  0.135  0.9660  0.4390  0.2145  0.2605  0.344828\n",
       "4174  1.0  0.600  0.475  0.205  1.1760  0.5255  0.2875  0.3080  0.310345\n",
       "4175  0.0  0.625  0.485  0.150  1.0945  0.5310  0.2610  0.2960  0.344828\n",
       "4176  1.0  0.710  0.555  0.195  1.9485  0.9455  0.3765  0.4950  0.413793\n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] = data[0]/data[0].max()\n",
    "data[8] = data[8]/data[8].max()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[data.columns[:-1]]\n",
    "y=data[data.columns[-1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.3905</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5805</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.0535</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.1405</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3341 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3       4       5       6      7\n",
       "4038  0.5  0.550  0.445  0.125  0.6720  0.2880  0.1365  0.210\n",
       "1272  0.5  0.475  0.355  0.100  0.5035  0.2535  0.0910  0.140\n",
       "3384  0.0  0.305  0.225  0.070  0.1485  0.0585  0.0335  0.045\n",
       "3160  0.5  0.275  0.200  0.065  0.1165  0.0565  0.0130  0.035\n",
       "3894  1.0  0.495  0.380  0.135  0.6295  0.2630  0.1425  0.215\n",
       "...   ...    ...    ...    ...     ...     ...     ...    ...\n",
       "3444  0.0  0.490  0.400  0.115  0.5690  0.2560  0.1325  0.145\n",
       "466   0.0  0.670  0.550  0.190  1.3905  0.5425  0.3035  0.400\n",
       "3092  1.0  0.510  0.395  0.125  0.5805  0.2440  0.1335  0.188\n",
       "3772  1.0  0.575  0.465  0.120  1.0535  0.5160  0.2185  0.235\n",
       "860   0.0  0.595  0.475  0.160  1.1405  0.5470  0.2310  0.271\n",
       "\n",
       "[3341 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5   , 0.55  , 0.445 , ..., 0.288 , 0.1365, 0.21  ],\n",
       "       [0.5   , 0.475 , 0.355 , ..., 0.2535, 0.091 , 0.14  ],\n",
       "       [0.    , 0.305 , 0.225 , ..., 0.0585, 0.0335, 0.045 ],\n",
       "       ...,\n",
       "       [1.    , 0.51  , 0.395 , ..., 0.244 , 0.1335, 0.188 ],\n",
       "       [1.    , 0.575 , 0.465 , ..., 0.516 , 0.2185, 0.235 ],\n",
       "       [0.    , 0.595 , 0.475 , ..., 0.547 , 0.231 , 0.271 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37931034],\n",
       "       [0.27586207],\n",
       "       [0.24137931],\n",
       "       ...,\n",
       "       [0.37931034],\n",
       "       [0.31034483],\n",
       "       [0.20689655]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2672 samples, validate on 669 samples\n",
      "Epoch 1/100\n",
      "2672/2672 [==============================] - 1s 316us/step - loss: 0.0409 - val_loss: 0.0082\n",
      "Epoch 2/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 4/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 5/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 6/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 7/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 8/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 9/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 10/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 11/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 13/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 14/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 15/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 16/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 17/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 18/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 19/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 20/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 21/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 22/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 23/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 24/100\n",
      "2672/2672 [==============================] - 0s 123us/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 25/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 26/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 27/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 28/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 29/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 30/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 31/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 32/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 33/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 34/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 35/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 36/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 37/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 38/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 39/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 40/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 41/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 42/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 43/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 44/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 45/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 46/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 47/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 48/100\n",
      "2672/2672 [==============================] - 0s 123us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 49/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 50/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 51/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 52/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 53/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 54/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 55/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 56/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 57/100\n",
      "2672/2672 [==============================] - 0s 110us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 58/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 59/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 60/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0056 - val_loss: 0.0069\n",
      "Epoch 61/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 62/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 63/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 64/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 65/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 66/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 67/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 68/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 69/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 70/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 71/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 72/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 73/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 74/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 75/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 76/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 77/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 78/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 79/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 80/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 81/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 82/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 83/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 84/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 85/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 86/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 87/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 88/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 89/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 90/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 91/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 92/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 93/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 94/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 95/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 96/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 97/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 98/100\n",
      "2672/2672 [==============================] - 0s 111us/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 99/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 100/100\n",
      "2672/2672 [==============================] - 0s 117us/step - loss: 0.0053 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "# 建構 model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, kernel_initializer=\"uniform\",activation='linear'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# 開始訓練 model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,257\n",
      "Trainable params: 4,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 顯示模型摘要與結構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.135469\n",
      "MAPE: 14.411308\n"
     ]
    }
   ],
   "source": [
    "# 評估指標\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "y_test = y_test * dfs_max\n",
    "preds = preds * dfs_max\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "mape = np.mean(np.abs((preds - y_test) / y_test)) * 100\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "\n",
    "# 畫圖\n",
    "# plt.plot(history.history['root_mean_squared_error'], label='root_mean_squared_error')\n",
    "# plt.plot(history.history['loss'], label='loss')\n",
    "# plt.plot(history.history['val_loss'], label='val_loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IDSL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.384980\n",
      "MAPE: 24.751226\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "svr = SVR(gamma=0.000000001,epsilon=0.001,C=1e3)\n",
    "# svr = SVR(kernel='rbf', gamma=scale, epsilon=0.001)\n",
    "# RMSE: 10.966594\n",
    "# MAPE: 26.509665\n",
    "\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "# 評估指標\n",
    "preds = svr.predict(X_test)\n",
    "\n",
    "y_test = y_test * dfs_max\n",
    "preds = preds * dfs_max\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "mape = np.mean(np.abs((preds - y_test) / y_test)) * 100\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "\n",
    "# 畫圖\n",
    "# plt.plot(history.history['root_mean_squared_error'], label='root_mean_squared_error')\n",
    "# plt.plot(history.history['loss'], label='loss')\n",
    "# plt.plot(history.history['val_loss'], label='val_loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IDSL\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.765047\n",
      "MAPE: 32.203476\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "RF = RandomForestRegressor(max_depth=1, random_state=0,n_estimators = 400)\n",
    "\n",
    "RF.fit(X_train,y_train)\n",
    "\n",
    "# 評估指標\n",
    "preds = RF.predict(X_test)\n",
    "\n",
    "y_test = y_test * dfs_max\n",
    "preds = preds * dfs_max\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "mape = np.mean(np.abs((preds - y_test) / y_test)) * 100\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "\n",
    "# 畫圖\n",
    "# plt.plot(history.history['root_mean_squared_error'], label='root_mean_squared_error')\n",
    "# plt.plot(history.history['loss'], label='loss')\n",
    "# plt.plot(history.history['val_loss'], label='val_loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.053904\n",
      "MAPE: 30.063891\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', booster = 'gblinear',\n",
    "                              reg_lambda = 0.1, learning_rate = 0.1, n_estimators = 55)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "# 評估指標\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "y_test = y_test * dfs_max\n",
    "preds = preds * dfs_max\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "mape = np.mean(np.abs((preds - y_test) / y_test)) * 100\n",
    "print(\"MAPE: %f\" % (mape))\n",
    "\n",
    "# 畫圖\n",
    "# plt.plot(history.history['root_mean_squared_error'], label='root_mean_squared_error')\n",
    "# plt.plot(history.history['loss'], label='loss')\n",
    "# plt.plot(history.history['val_loss'], label='val_loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
